{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn56W8FECctz3qp1pBx6im",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8a259a928864abea159eccc35050fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e581112f2984c11b2d4b21215941d19",
              "IPY_MODEL_7581befb26264bc9ae24e29ee08f0924",
              "IPY_MODEL_787872e82a9c4850906a2a28e2a36537"
            ],
            "layout": "IPY_MODEL_0ef6951430cf4ab6b235c88c229beafc"
          }
        },
        "9e581112f2984c11b2d4b21215941d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482233cf6a8946dc87ccc91cba189320",
            "placeholder": "​",
            "style": "IPY_MODEL_b67b8ba5a4b64873acbd237cde5046cf",
            "value": "Map: 100%"
          }
        },
        "7581befb26264bc9ae24e29ee08f0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0d3e95d6494cf984ed92c6b52004de",
            "max": 4371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcee2f1798f24737ad912630f8cf5c0b",
            "value": 4371
          }
        },
        "787872e82a9c4850906a2a28e2a36537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5835b1edcfbd455d84c679104abbaaaf",
            "placeholder": "​",
            "style": "IPY_MODEL_7002c64ce37a4d93bc55c9978b8e93e4",
            "value": " 4371/4371 [00:01&lt;00:00, 3451.28 examples/s]"
          }
        },
        "0ef6951430cf4ab6b235c88c229beafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482233cf6a8946dc87ccc91cba189320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67b8ba5a4b64873acbd237cde5046cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0d3e95d6494cf984ed92c6b52004de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcee2f1798f24737ad912630f8cf5c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5835b1edcfbd455d84c679104abbaaaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7002c64ce37a4d93bc55c9978b8e93e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaCoZu/NLP/blob/main/06_gtp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g53c-lLHsmlu",
        "outputId": "9e6e52f0-701d-44ea-b484-8c39a8e9b69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd /content/drive/MyDrive/Colab Notebooks/NLP\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2P_9Sx37Hkd",
        "outputId": "34f5b2b6-41a4-499c-ef7d-4e5c1c1db820"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: too many arguments\n",
            "dataset.txt  drive  sample_data  tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.28.0 tokenizers datasets accelerate"
      ],
      "metadata": {
        "id": "0OKPQ1p5tCKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "tf.config.list_physical_devices(\"GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKV3ics4syfk",
        "outputId": "2d18397c-ccf1-4f40-8703-871c25e114ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "NIz6Dl14tiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_file = \"dataset.txt\"\n",
        "\n",
        "# How many files to load.\n",
        "file_number = 100\n",
        "\n",
        "# Clone the repo.\n",
        "!git clone https://github.com/vilmibm/lovecraftcorpus\n",
        "\n",
        "# Find all the files.\n",
        "paths = glob.glob(\"lovecraftcorpus/*.txt\")\n",
        "\n",
        "# Do not use all.\n",
        "paths = paths[:file_number]\n",
        "print(sorted(paths))\n",
        "\n",
        "# Merge.\n",
        "with open(dataset_file, \"w\") as output_file:\n",
        "    for path in paths:\n",
        "        for line in open(path, \"r\"):\n",
        "            for split in line.split(\"\\n\"):\n",
        "                split = split.strip()\n",
        "                if split != \"\":\n",
        "                    print(split, file=output_file)\n",
        "\n",
        "# Delete repo.\n",
        "!rm -rf lovecraftcorpus\n",
        "\n",
        "# Done.\n",
        "print(\"Corpus downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5_1A-LWtkOJ",
        "outputId": "3dd2703c-ea53-468f-ebbd-3465c54db339"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'lovecraftcorpus' already exists and is not an empty directory.\n",
            "['lovecraftcorpus/alchemist.txt', 'lovecraftcorpus/arthur_jermyn.txt', 'lovecraftcorpus/azathoth.txt', 'lovecraftcorpus/beast.txt', 'lovecraftcorpus/beyond_wall_of_sleep.txt', 'lovecraftcorpus/book.txt', 'lovecraftcorpus/celephais.txt', 'lovecraftcorpus/charles_dexter_ward.txt', 'lovecraftcorpus/clergyman.txt', 'lovecraftcorpus/colour_out_of_space.txt', 'lovecraftcorpus/cool_air.txt', 'lovecraftcorpus/crawling_chaos.txt', 'lovecraftcorpus/cthulhu.txt', 'lovecraftcorpus/dagon.txt', 'lovecraftcorpus/descendent.txt', 'lovecraftcorpus/doorstep.txt', 'lovecraftcorpus/dreams_in_the_witch.txt', 'lovecraftcorpus/dunwich.txt', 'lovecraftcorpus/erich_zann.txt', 'lovecraftcorpus/ex_oblivione.txt', 'lovecraftcorpus/festival.txt', 'lovecraftcorpus/from_beyond.txt', 'lovecraftcorpus/gates_of_silver_key.txt', 'lovecraftcorpus/haunter.txt', 'lovecraftcorpus/he.txt', 'lovecraftcorpus/high_house_mist.txt', 'lovecraftcorpus/hound.txt', 'lovecraftcorpus/hypnos.txt', 'lovecraftcorpus/innsmouth.txt', 'lovecraftcorpus/iranon.txt', 'lovecraftcorpus/juan_romero.txt', 'lovecraftcorpus/kadath.txt', 'lovecraftcorpus/lurking_fear.txt', 'lovecraftcorpus/martins_beach.txt', 'lovecraftcorpus/medusas_coil.txt', 'lovecraftcorpus/memory.txt', 'lovecraftcorpus/moon_bog.txt', 'lovecraftcorpus/mountains_of_madness.txt', 'lovecraftcorpus/nameless.txt', 'lovecraftcorpus/nyarlathotep.txt', 'lovecraftcorpus/old_folk.txt', 'lovecraftcorpus/other_gods.txt', 'lovecraftcorpus/outsider.txt', 'lovecraftcorpus/pharoahs.txt', 'lovecraftcorpus/pickman.txt', 'lovecraftcorpus/picture_house.txt', 'lovecraftcorpus/poetry_of_gods.txt', 'lovecraftcorpus/polaris.txt', 'lovecraftcorpus/randolph_carter.txt', 'lovecraftcorpus/rats_walls.txt', 'lovecraftcorpus/reanimator.txt', 'lovecraftcorpus/redhook.txt', 'lovecraftcorpus/sarnath.txt', 'lovecraftcorpus/shadow_out_of_time.txt', 'lovecraftcorpus/shunned_house.txt', 'lovecraftcorpus/silver_key.txt', 'lovecraftcorpus/street.txt', 'lovecraftcorpus/temple.txt', 'lovecraftcorpus/terrible_old_man.txt', 'lovecraftcorpus/tomb.txt', 'lovecraftcorpus/tree.txt', 'lovecraftcorpus/ulthar.txt', 'lovecraftcorpus/unnamable.txt', 'lovecraftcorpus/vault.txt', 'lovecraftcorpus/what_moon_brings.txt', 'lovecraftcorpus/whisperer.txt', 'lovecraftcorpus/white_ship.txt']\n",
            "Corpus downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"text\", data_files=[dataset_file])\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhZxRt1Ct9Ht",
        "outputId": "8fb28d57-2be1-48df-f708-aedb9fd6c58d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 4371\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range (10):\n",
        "  token_sequence = raw_datasets[\"train\"][index]\n",
        "  print(token_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6C5U_3oucA9",
        "outputId": "5aa7759a-4cad-4bc8-fd81-cf4a566d51cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"PICKMAN'S MODEL\"}\n",
            "{'text': \"I know I'm more nervous than I was when you saw me last year, but you don't need to hold a clinic over it. There's plenty of reason, God knows, and I fancy I'm lucky to be sane at all. Why the third degree? You didn't use to be so inquisitive.\"}\n",
            "{'text': \"Well, if you must hear it, I don't know why you shouldn't. Maybe you ought to, anyhow, for you kept writing me like a grieved parent when you heard I'd begun to cut the Art Club and keep away from Pickman. Now that he's disappeared I go round to the club once in a while, but my nerves aren't what they were.\"}\n",
            "{'text': \"No, I don't know what's become of Pickman, and I don't like to guess. You might have surmised I had some inside information when I dropped him--and that's why I don't want to think where he's gone. Let the police find what they can--it won't be much, judging from the fact that they don't know yet of the old North End place he hired under the name of Peters.\"}\n",
            "{'text': \"I'm not sure that I could find it again myself--not that I'd ever try, even in broad daylight!\"}\n",
            "{'text': \"Yes, I do know, or am afraid I know, why he maintained it. I'm coming to that. And I think you'll understand before I'm through why I don't tell the police. They would ask me to guide them, but I couldn't go back there even if I knew the way. There was something there--and now I can't use the subway or (and you may as well have your laugh at this, too) go down into cellars any more.\"}\n",
            "{'text': \"I should think you'd have known I didn't drop Pickman for the same silly reasons that fussy old women like Dr. Reid or Joe Minot or Rosworth did. Morbid art doesn't shock me, and when a man has the genius Pickman had I feel it an honour to know him, no matter what direction his work takes. Boston never had a greater painter than Richard Upton Pickman. I said it at first and I say it still, and I never swerved an inch, either, when he showed that 'Ghoul Feeding'. That, you remember, was when Minot cut him.\"}\n",
            "{'text': \"You know, it takes profound art and profound insight into Nature to turn out stuff like Pickman's. Any magazine-cover hack can splash paint around wildly and call it a nightmare or a Witches' Sabbath or a portrait of the devil, but only a great painter can make such a thing really scare or ring true. That's because only a real artist knows the actual anatomy of the terrible or the physiology of fear-the exact sort of lines and proportions that connect up with latent instincts or hereditary memories of fright, and the proper colour contrasts and lighting effects to stir the dormant sense of strangeness. I don't have to tell you why a Fuseli really brings a shiver while a cheap ghost-story frontispiece merely makes us laugh. There's something those fellows catch--beyond life--that they're able to make us catch for a second. Doré had it. Sime has it. Angarola of Chicago has it. And Pickman had it as no man ever had it before or--I hope to Heaven--ever will again.\"}\n",
            "{'text': \"Don't ask me what it is they see. You know, in ordinary art, there's all the difference in the world between the vital, breathing things drawn from Nature or models and the artificial truck that commercial small fry reel off in a bare studio by rule. Well, I should say that the really weird artist has a kind of vision which makes models, or summons up what amounts to actual scenes from the spectral world he lives in. Anyhow, he manages to turn out results that differ from the pretender's mince-pie dreams in just about the same way that the life painter's results differ from the concoctions of a correspondence--school cartoonist. If I had ever seen what Pickman saw--but no! Here, let's have a drink before we get any deeper. God, I wouldn't be alive if I'd ever seen what that man--if he was a man--saw&#160;!\"}\n",
            "{'text': \"You recall that Pickman's forte was faces. I don't believe anybody since Goya could put so much of sheer hell into a set of features or a twist of expression. And before Goya you have to go back to the mediaeval chaps who did the gargoyles and chimaeras on Notre Dame and Mont Saint-Michel. They believed all sorts of things--and maybe they saw all sorts of things, too, for the Middle Ages had some curious phases I remember your asking Pickman yourself once, the year before you went away, wherever in thunder he got such ideas and visions. Wasn't that a nasty laugh he gave you? It was partly because of that laugh that Reid dropped him. Reid, you know, had just taken up comparative pathology, and was full of pompous 'inside stuff' about the biological or evolutionary significance of this or that mental or physical symptom. He said Pickman repelled him more and more every day, and almost frightened him towards the last--that the fellow's features and expression were slowly developing in a way he didn't like; in a way that wasn't human. He had a lot of talk about diet, and said Pickman must be abnormal and eccentric to the last degree. I suppose you told Reid, if you and he had any correspondence over it, that he'd let Pickman's paintings get on his nerves or harrow up his imagination. I know I told him that myself--then.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "nVzcVPILu8ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=5000, special_tokens=[\"[UNK]\", \"[PAD]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "\n",
        "def batch_iterator(batch_size=1000):\n",
        "  for i in range(0, len(raw_datasets[\"train\"]), batch_size):\n",
        "    yield raw_datasets[\"train\"][i: i + batch_size][\"text\"]\n",
        "\n",
        "tokenizer.train_from_iterator(\n",
        "    batch_iterator(),\n",
        "    trainer=trainer,\n",
        "    length=len(raw_datasets[\"train\"])\n",
        "    )\n",
        "\n",
        "tokenizer.save(\"tokenizer.json\")\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer.json\")\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMPgQ78MvCSt",
        "outputId": "f057ec34-20da-4b48-9392-b7def7da4202"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGXslW1dz5MG",
        "outputId": "cbb507a5-a3cb-43ea-eb31-3d698d755151"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"What's up!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plwz2zBG0BSk",
        "outputId": "bff8e349-b9a2-4b3e-e05f-3360149ece07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[967, 6, 71, 225, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "1GkAlwpK0nTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 256\n",
        "\n",
        "def tokenize_function(example):\n",
        "  tokenized_example = tokenizer(\n",
        "      example[\"text\"],\n",
        "      truncation=True,\n",
        "      padding=True,\n",
        "      max_length=sequence_length\n",
        "      )\n",
        "\n",
        "  return {\"input_ids\": tokenized_example[\"input_ids\"]}\n",
        "\n",
        "token_sequence = raw_datasets[\"train\"][666]\n",
        "print(token_sequence)\n",
        "\n",
        "tokenized = tokenize_function(token_sequence)\n",
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rQnnZZc0qDm",
        "outputId": "30cf7212-dee7-4f7e-cb5e-81da217b81ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'It was a paw, fully two feet and a half across, and equipped with formidable talons. After it came another paw, and after that a great black-furred arm to which both of the paws were attached by short forearms. Then two pink eyes shone, and the head of the awakened Gug sentry, large as a barrel, wabbled into view. The eyes jutted two inches from each side, shaded by bony protuberances overgrown with coarse hairs. But the head was chiefly terrible because of the mouth. That mouth had great yellow fangs and ran from the top to the bottom of the head, opening vertically instead of horizontally.'}\n",
            "{'input_ids': [288, 127, 53, 68, 208, 9, 877, 542, 795, 102, 53, 630, 1119, 9, 102, 1820, 430, 439, 152, 378, 133, 274, 434, 955, 11, 1149, 113, 361, 814, 68, 208, 9, 102, 371, 128, 53, 348, 462, 10, 917, 166, 2212, 111, 182, 880, 103, 93, 4254, 194, 626, 3335, 213, 1634, 300, 2967, 11, 538, 542, 68, 443, 690, 3575, 9, 102, 93, 475, 103, 93, 208, 255, 485, 33, 698, 982, 508, 9, 949, 109, 53, 1068, 695, 9, 75, 147, 831, 351, 1232, 11, 184, 690, 62, 146, 299, 542, 4845, 187, 1028, 428, 9, 850, 96, 213, 54, 1151, 279, 1698, 471, 1288, 319, 2188, 152, 268, 2535, 60, 1146, 11, 528, 93, 475, 127, 2698, 118, 750, 753, 103, 93, 2011, 11, 738, 2011, 132, 348, 1587, 58, 395, 71, 102, 1317, 187, 93, 1277, 111, 93, 2197, 103, 93, 475, 9, 2479, 3094, 1169, 2753, 103, 2636, 1270, 298, 11]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names\n",
        "    )\n",
        "\n",
        "print(tokenized_datasets[\"train\"][666].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "c8a259a928864abea159eccc35050fe4",
            "9e581112f2984c11b2d4b21215941d19",
            "7581befb26264bc9ae24e29ee08f0924",
            "787872e82a9c4850906a2a28e2a36537",
            "0ef6951430cf4ab6b235c88c229beafc",
            "482233cf6a8946dc87ccc91cba189320",
            "b67b8ba5a4b64873acbd237cde5046cf",
            "7c0d3e95d6494cf984ed92c6b52004de",
            "dcee2f1798f24737ad912630f8cf5c0b",
            "5835b1edcfbd455d84c679104abbaaaf",
            "7002c64ce37a4d93bc55c9978b8e93e4"
          ]
        },
        "id": "v_TCtJJv2ZL4",
        "outputId": "92bbd0c2-d0c2-4531-82be-54a63c54ea32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4371 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8a259a928864abea159eccc35050fe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer,\n",
        "    mlm=False,\n",
        ")"
      ],
      "metadata": {
        "id": "48-fP5SK3kJl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "id": "Zq7WHcMI4AwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = GPT2Config(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    n_ctx = sequence_length,\n",
        "    n_positions=sequence_length,\n",
        "    n_embd=512,\n",
        "    n_head=8,\n",
        "    n_layer=6\n",
        ")\n",
        "\n",
        "model = GPT2LMHeadModel(model_config)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F5ZkF1j4Cvu",
        "outputId": "ffa5d0d1-f67f-48b4-d734-38d39d87a7fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(5000, 512)\n",
              "    (wpe): Embedding(256, 512)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x GPT2Block(\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=5000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"output\"\n",
        "\n",
        "\n",
        "training_args =TrainingArguments(\n",
        "    output_dir=output_path,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    prediction_loss_only=False\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets[\"train\"]\n",
        ")"
      ],
      "metadata": {
        "id": "SJgC6_0I6hEb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "Y0XMMKFn8YAH",
        "outputId": "756e471e-b72f-4404-c88d-dad04985a3e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2735' max='2735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2735/2735 05:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.989800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>5.780000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.649400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>5.571400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2735, training_loss=5.867340411477376, metrics={'train_runtime': 344.0374, 'train_samples_per_second': 63.525, 'train_steps_per_second': 7.95, 'total_flos': 634973941923840.0, 'train_loss': 5.867340411477376, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(output_path)\n",
        "model.save_pretrained(output_path)"
      ],
      "metadata": {
        "id": "Qp_-kvR29FGI"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}